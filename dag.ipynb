{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import lucid.modelzoo.vision_models as models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get general information of InceptionV1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(graph_nodes):\n",
    "    '''\n",
    "    Get all layers\n",
    "    * input\n",
    "        - graph_nodes: tensorflow graph nodes\n",
    "    * output\n",
    "        - layers: list of all layers\n",
    "    '''\n",
    "    layers = []\n",
    "    for n in graph_nodes:\n",
    "        node_name = n.name\n",
    "        if node_name[-2:] == '_w':\n",
    "            layer = node_name.split('_')[0]\n",
    "            if layer not in layers:\n",
    "                layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_sizes(layer, weight_nodes):\n",
    "    '''\n",
    "    Get channel sizes\n",
    "    * input\n",
    "        - layer: the name of layer\n",
    "        - weight_nodes: tensorflow nodes for all filters\n",
    "    * output\n",
    "        - channel_sizes: list of channel size for all pre-concatenated blocks\n",
    "    '''\n",
    "    \n",
    "    channel_sizes = [get_shape_of_node(n)[0] for n in weight_nodes if layer in n.name and '_b' == n.name[-2:] and 'bottleneck' not in n.name]\n",
    "    return channel_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_of_node(n):\n",
    "    '''\n",
    "    Get the shape of the tensorflow node\n",
    "    * input\n",
    "        - n: tensorflow node\n",
    "    * output\n",
    "        - tensor_shape: shape of n\n",
    "    '''\n",
    "    dims = n.attr['value'].tensor.tensor_shape.dim\n",
    "    tensor_shape = [d.size for d in dims]\n",
    "    return tensor_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DAG and save it into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_I_matrices(all_layers, start_layer, end_layer):\n",
    "    \n",
    "# Get layers starting from the given layer to the input layer\n",
    "    start_idx, end_idx = all_layers.index(start_layer), all_layers.index(end_layer)\n",
    "    target_layers = all_layers[start_idx: end_idx - 1: -1]\n",
    "\n",
    "    # Load I matrices\n",
    "    Is = {}\n",
    "    for layer in target_layers:\n",
    "        print('loading ', layer)\n",
    "        Is[layer] = load_inf_matrix(I_mat_dirpath, layer)\n",
    "        for branch in [1, 2]:\n",
    "            inner_layer = '{}_{}'.format(layer, branch)\n",
    "            Is[inner_layer] = load_inf_matrix(I_mat_dirpath, inner_layer)\n",
    "            \n",
    "    return Is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_save_dag(Is, pred_class, I_mat_dirpath, dag_dirpath, channels, layer_fragment_sizes, dag_k=3, start_layer='mixed5b', end_layer='mixed3a'):\n",
    "    '''\n",
    "    Generate DAG and save it into a file\n",
    "    * input\n",
    "        - pred_class: predicted class\n",
    "        - all_layers: all layers\n",
    "        - I_mat_dirpath: directory path of I-matrices\n",
    "        - dag_dirpath: direcgtory path of dag\n",
    "        - channels: starting channels in start_layer (towrards output)\n",
    "        - layer_fragment_sizes: sizes of fragments in all layers\n",
    "        - dag_k: the number of top impactful previous channels\n",
    "        - start_layer: start layer (towards output)\n",
    "        - end_layer: end layer (towards input)\n",
    "    * output\n",
    "        - N/A\n",
    "    '''\n",
    "\n",
    "    # Get dags\n",
    "    dags = gen_impactful_dags(Is, start_layer, channels, pred_class, all_layers, layer_fragment_sizes, k=dag_k, end_layer=end_layer)\n",
    "\n",
    "    # Save dags\n",
    "    filename = dag_dirpath + 'dag-{}.json'.format(pred_class)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dags, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inf_matrix(mat_dirpath, layer):\n",
    "    '''\n",
    "    Load I matrix\n",
    "    * input\n",
    "        - mat_dirpath: directory path of I-matrices\n",
    "        - layer: layer name\n",
    "    * output\n",
    "        - I_mat: I-matrix of the given layer\n",
    "    '''\n",
    "    if mat_dirpath[-1] == '/':\n",
    "        filepath = mat_dirpath + 'I_' + layer + '.json'\n",
    "    else:\n",
    "        filepath = mat_dirpath + '/I_' + layer + '.json'\n",
    "        \n",
    "    with open(filepath) as f:\n",
    "        I_mat = json.load(f)\n",
    "    \n",
    "    return I_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_impactful_dags(Is, layer, channels, pred_class, all_layers, layer_fragment_sizes, k=3, end_layer='mixed3a'):\n",
    "    '''\n",
    "    Generate impactful dags starting from channels in a layer to input layer\n",
    "    * input\n",
    "        - Is: influence matrices\n",
    "        - layer: starting layer\n",
    "        - channels: selected channels in the layer\n",
    "        - pred_class: predicted class\n",
    "        - all_layers: all layers\n",
    "        - layer_fragment_sizes: sizes of fragments in all layers\n",
    "        - k: the number of top impactful previous channels\n",
    "        - end_layer: end layer (towards input)\n",
    "    * output\n",
    "        - dags: a dictionary, whose\n",
    "            - key: a layer\n",
    "            - val: a dictionary, which maps\n",
    "                - key: a neuron in current layer\n",
    "                - val: list of important neurons in the previous layer\n",
    "    '''\n",
    "    \n",
    "    # Get layers starting from the given layer to the input layer\n",
    "    start_idx, end_idx = all_layers.index(layer), all_layers.index(end_layer)\n",
    "    target_layers = all_layers[start_idx: end_idx - 1: -1]\n",
    "    \n",
    "    # Initialize the dags\n",
    "    dags = {}\n",
    "    \n",
    "    # Record of what channels have been added to which layers\n",
    "    record = {}\n",
    "    \n",
    "    # Aggregate the dags across layers\n",
    "    curr_channels = channels[:]\n",
    "    for curr_layer in target_layers:\n",
    "        dags[curr_layer] = []\n",
    "        record[curr_layer] = set()\n",
    "        agg_prev_channels = []\n",
    "        \n",
    "        for curr_channel in curr_channels:\n",
    "            \n",
    "            # if this channel is already in the DAG, skip\n",
    "            if curr_channel in record[curr_layer]:\n",
    "                pass\n",
    "            \n",
    "            # if this channel isn't in the DAG, do the regular computation\n",
    "            else:\n",
    "                prev_channels, prev_infs = get_top_prevs(Is, curr_layer, curr_channel, pred_class, layer_fragment_sizes[curr_layer], k=k)\n",
    "                curr_channel_dict = {'channel': curr_channel, 'prev_channels': []}\n",
    "                for prev_c, prev_inf in zip(prev_channels, prev_infs):\n",
    "                    curr_channel_dict['prev_channels'].append({'prev_channel': prev_c, 'inf': prev_inf})\n",
    "                dags[curr_layer].append(curr_channel_dict)\n",
    "                record[curr_layer].add(curr_channel)\n",
    "                agg_prev_channels += prev_channels\n",
    "        curr_channels = agg_prev_channels[:]\n",
    "    \n",
    "    return dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_prevs(I_layers, layer, channel, pred_class, layer_channels, k=3):\n",
    "    '''\n",
    "    Get top impactful channels in previous layer\n",
    "    * input\n",
    "        - I_layers: a dictionary for influence matrices for the layer\n",
    "            - key: layer\n",
    "            - val: influence matrix of the layer\n",
    "        - layer: the name of layer\n",
    "        - channel: channel in the layer\n",
    "        - pred_class: the predicted class\n",
    "        - layer_channels: sizes of fragments in the layer\n",
    "        - k: the number of top impactful previous channels\n",
    "    * output\n",
    "        - top_prev_channels: top k impactful previous channels\n",
    "        - top_prev_infs: influences of the top k impactful previous channels\n",
    "    '''\n",
    "    \n",
    "    # Get influences\n",
    "    infs = I_layers[layer][pred_class][channel]\n",
    "    \n",
    "    # Get top k previous channels\n",
    "    top_prev_channels = sorted(infs, key=infs.get, reverse=True)[:k]\n",
    "    top_prev_infs = [infs[c] for c in top_prev_channels]\n",
    "    top_prev_channels = [int(c) for c in top_prev_channels]\n",
    "        \n",
    "    # Figure out which branch is connected to the channel\n",
    "    branch = get_branch(layer, channel, layer_channels)\n",
    "    \n",
    "    # If the branch goes through inner layers\n",
    "    if branch in [1, 2]:\n",
    "        inner_layer = '{}_{}'.format(layer, branch)\n",
    "        inf_inner = I_layers[inner_layer][pred_class]\n",
    "        top_infs = defaultdict(lambda: 0)\n",
    "                \n",
    "        for prev_channel in top_prev_channels:\n",
    "            prev_infs = inf_inner[prev_channel]\n",
    "            for prev_prev_channel in prev_infs.keys():\n",
    "                top_infs[prev_prev_channel] += prev_infs[prev_prev_channel]\n",
    "        top_prev_prev_channels = sorted(top_infs, key=top_infs.get, reverse=True)[:k]\n",
    "        top_prev_prev_infs = [top_infs[c] for c in top_prev_prev_channels]\n",
    "        top_prev_prev_channels = [int(c) for c in top_prev_prev_channels]\n",
    "        \n",
    "        return top_prev_prev_channels, top_prev_prev_infs\n",
    "        \n",
    "    else:\n",
    "        return top_prev_channels, top_prev_infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch(layer, channel, layer_channels):\n",
    "    '''\n",
    "    Get branch of the channel in the layer\n",
    "    * input\n",
    "        - layer: the name of layer\n",
    "        - channel: channel in the layer\n",
    "        - layer_channels: fragment sizes of the layer\n",
    "    * output\n",
    "        - branch: branch of the channel\n",
    "    '''\n",
    "    \n",
    "    channels = layer_channels[:]\n",
    "    for i in range(len(channels) - 1):\n",
    "        channels[i + 1] += channels[i]\n",
    "        \n",
    "    branch = np.searchsorted(channels, channel, side='right')\n",
    "    \n",
    "    return branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN - Generate DAGs for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dirpath = './'\n",
    "I_mat_dirpath = main_dirpath + 'data/I-matrices/'\n",
    "dag_dirpath = main_dirpath + 'data/dag/'\n",
    "imgnet_dirpath = main_dirpath + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_layer = 'mixed5b'\n",
    "end_layer = 'mixed3a'\n",
    "dag_k = 3\n",
    "num_class = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()\n",
    "nodes = googlenet.graph_def.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers = get_layers(nodes)\n",
    "mixed_layers = [layer for layer in all_layers if 'mixed' in layer]\n",
    "layer_fragment_sizes = {layer: get_channel_sizes(layer, nodes) for layer in mixed_layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(imgnet_dirpath + 'imagenet.json') as f:\n",
    "    imgnet = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  mixed5b\n",
      "loading  mixed5a\n",
      "loading  mixed4e\n",
      "loading  mixed4d\n",
      "loading  mixed4c\n",
      "loading  mixed4b\n",
      "loading  mixed4a\n",
      "loading  mixed3b\n",
      "loading  mixed3a\n"
     ]
    }
   ],
   "source": [
    "Is = load_I_matrices(all_layers, start_layer, end_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for pred_class in range(num_class):\n",
    "    if pred_class % 100 == 0:\n",
    "        print(pred_class)\n",
    "    \n",
    "    prev_counter = imgnet[pred_class]['topChannels'][start_layer]\n",
    "    channels = [prev_counter[i]['channel'] for i in range(dag_k)]\n",
    "    generate_save_dag(Is, pred_class, I_mat_dirpath, dag_dirpath, channels, layer_fragment_sizes, 3, start_layer, end_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kit fox, mixed5b\n",
    "# pred_class = 278\n",
    "# channels = [765,186,270]\n",
    "\n",
    "# white wolf, mixed4c\n",
    "# pred_class = 270\n",
    "# channels = [264,216]\n",
    "\n",
    "# white wolf, mixed5b\n",
    "# pred_class = 270\n",
    "# channels = [821,101,116]\n",
    "\n",
    "# fire engine, mixed5b\n",
    "# pred_class = 555\n",
    "# channels = [876,881,661]\n",
    "\n",
    "# # fire engine, mixed5a\n",
    "# pred_class = 555\n",
    "# channels = [581,432,586]\n",
    "\n",
    "# strawberry, mixed5a, tfr1\n",
    "# pred_class = 949\n",
    "# channels = [306,504,20]\n",
    "\n",
    "# generate_save_dag(pred_class, all_layers, I_mat_dirpath, dag_dirpath, channels, layer_fragment_sizes, 3, 'mixed5b', 'mixed4b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
