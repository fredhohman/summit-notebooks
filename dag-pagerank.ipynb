{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import lucid.modelzoo.vision_models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to get general information of inception_v1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(graph_nodes):\n",
    "    '''\n",
    "    Get all layers\n",
    "    * input\n",
    "        - graph_nodes: tensorflow graph nodes\n",
    "    * output\n",
    "        - layers: list of all layers\n",
    "    '''\n",
    "    layers = []\n",
    "    for n in graph_nodes:\n",
    "        node_name = n.name\n",
    "        if node_name[-2:] == '_w':\n",
    "            layer = node_name.split('_')[0]\n",
    "            if layer not in layers:\n",
    "                layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_sizes(layer, weight_nodes):\n",
    "    '''\n",
    "    Get channel sizes\n",
    "    * input\n",
    "        - layer: the name of layer\n",
    "        - weight_nodes: tensorflow nodes for all filters\n",
    "    * output\n",
    "        - channel_sizes: list of channel size for all pre-concatenated blocks\n",
    "    '''\n",
    "    \n",
    "    channel_sizes = [get_shape_of_node(n)[0] for n in weight_nodes if layer in n.name and '_b' == n.name[-2:] and 'bottleneck' not in n.name]\n",
    "    return channel_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_of_node(n):\n",
    "    '''\n",
    "    Get the shape of the tensorflow node\n",
    "    * input\n",
    "        - n: tensorflow node\n",
    "    * output\n",
    "        - tensor_shape: shape of n\n",
    "    '''\n",
    "    dims = n.attr['value'].tensor.tensor_shape.dim\n",
    "    tensor_shape = [d.size for d in dims]\n",
    "    return tensor_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract influences from I-matrices for a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_class_I_matrices(Is, all_layers, start_layer, end_layer, pred_class, verbose=True):\n",
    "    '''\n",
    "    Extract influences for a class from I-matrices\n",
    "    * input\n",
    "        - Is: I-matrices for all class\n",
    "        - all_layers: list of all layers\n",
    "        - start_layer: start layer (towards output)\n",
    "        - end_layer: end layer (towards input)\n",
    "        - pred_class: predicted class\n",
    "    * output\n",
    "        - Is_class: I-matrices for a class. a dictionary, where\n",
    "            - key: layer name (e.g. 'mixed4d', 'mixed4d_1')\n",
    "            - val: influences for given layer(key), class(argument of the function)\n",
    "    '''\n",
    "\n",
    "    # Get layers starting from the given layer to the input layer\n",
    "    start_idx, end_idx = all_layers.index(start_layer), all_layers.index(end_layer)\n",
    "    target_layers = all_layers[start_idx: end_idx - 1: -1]\n",
    "    \n",
    "    Is_class = {}\n",
    "    \n",
    "    for layer in target_layers:\n",
    "        if verbose:\n",
    "            print('\\n({}) loading {}'.format(pred_class, layer), end='')\n",
    "        Is_class[layer] = Is[layer][pred_class]\n",
    "        for branch in [1, 2]:\n",
    "            inner_layer = '{}_{}'.format(layer, branch)\n",
    "            if verbose:\n",
    "                print(',', inner_layer, end='')\n",
    "            Is_class[inner_layer] = Is[inner_layer][pred_class]\n",
    "    if verbose:\n",
    "        print('\\n')\n",
    "    \n",
    "    return Is_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_I_matrices(all_layers, start_layer, end_layer, I_mat_dirpath, verbose=True):\n",
    "    '''\n",
    "    Load I-matrices for all layers\n",
    "    * input\n",
    "        - all_layers: list of all layers\n",
    "        - start_layer: start layer (towards output)\n",
    "        - end_layer: end layer (towards input)\n",
    "        - I_mat_dirpath: directory path of I-matrices\n",
    "    * output\n",
    "        - Is: I-matrices for all class\n",
    "    '''\n",
    "    \n",
    "    # Get layers starting from the given layer to the input layer\n",
    "    start_idx, end_idx = all_layers.index(start_layer), all_layers.index(end_layer)\n",
    "    target_layers = all_layers[start_idx: end_idx - 1: -1]\n",
    "\n",
    "    # Load I matrices\n",
    "    Is = {}\n",
    "    for layer in target_layers:\n",
    "        if verbose:\n",
    "            print('\\n(all) loading {}'.format(layer), end='')\n",
    "        Is[layer] = load_inf_matrix(I_mat_dirpath, layer)\n",
    "        for branch in [1, 2]:\n",
    "            inner_layer = '{}_{}'.format(layer, branch)\n",
    "            if verbose:\n",
    "                print(',', inner_layer, end='')\n",
    "            Is[inner_layer] = load_inf_matrix(I_mat_dirpath, inner_layer)\n",
    "    if verbose:\n",
    "        print('\\n')    \n",
    "    return Is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inf_matrix(I_mat_dirpath, layer):\n",
    "    '''\n",
    "    Load I matrix for a layer\n",
    "    * input\n",
    "        - mat_dirpath: directory path of I-matrices\n",
    "        - layer: layer name\n",
    "    * output\n",
    "        - I_mat: I-matrix of the given layer\n",
    "    '''\n",
    "    if I_mat_dirpath[-1] == '/':\n",
    "        filepath = I_mat_dirpath + 'I_' + layer + '.json'\n",
    "    else:\n",
    "        filepath = I_mat_dirpath + '/I_' + layer + '.json'\n",
    "        \n",
    "    with open(filepath) as f:\n",
    "        I_mat = json.load(f)\n",
    "    \n",
    "    return I_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract M-matrices information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_M(M_mat_dirpath, layer):\n",
    "    M = np.loadtxt(M_mat_dirpath + 'M-' + layer + '.csv', delimiter=',', dtype=int)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Ms(M_mat_dirpath, mixed_layers):\n",
    "    Ms = {}\n",
    "    for layer in mixed_layers:\n",
    "        M = read_M(M_mat_dirpath, layer)\n",
    "        Ms[layer] = M\n",
    "    return Ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to query the influence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch(layer, channel, layer_channels):\n",
    "    '''\n",
    "    Get branch of the channel in the layer\n",
    "    * input\n",
    "        - layer: the name of layer\n",
    "        - channel: channel in the layer\n",
    "        - layer_channels: fragment sizes of the layer\n",
    "    * output\n",
    "        - branch: branch of the channel\n",
    "    '''\n",
    "    \n",
    "    channels = layer_channels[:]\n",
    "    for i in range(len(channels) - 1):\n",
    "        channels[i + 1] += channels[i]\n",
    "        \n",
    "    branch = np.searchsorted(channels, channel, side='right')\n",
    "    \n",
    "    return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_num_of_prevs_for_a_channel(layer, Is_class):\n",
    "    '''\n",
    "    Get the average number of previous channels connected to a channel in the given layer\n",
    "    * input\n",
    "        - layer: layer\n",
    "        - Is_class: I-matrices for a class\n",
    "    * output\n",
    "        - num_avg: the average number of connections for a channel in the given layer\n",
    "    '''\n",
    "    \n",
    "    num_of_channel_edges = []\n",
    "    \n",
    "    for channel, prev_inf_dict in enumerate(Is_class[layer]):\n",
    "        # Get branch\n",
    "        branch = get_branch(layer, channel, layer_fragment_sizes[layer])\n",
    "        \n",
    "        if branch in [0, 3]:\n",
    "            num_of_channel_edges.append(len(prev_inf_dict))\n",
    "            \n",
    "    num_avg = int(np.average(num_of_channel_edges))\n",
    "    \n",
    "    return num_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_name(layer, channel):\n",
    "    return layer + '-' + str(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_full_graph(Is_class, G, mixed_layers):\n",
    "    \n",
    "    # Add edges into G from Is_class\n",
    "    for layer_idx, layer in enumerate(mixed_layers[::-1][:-1]):\n",
    "        # Get previous layer\n",
    "        prev_layer = mixed_layers[::-1][layer_idx + 1]\n",
    "        \n",
    "        # Get the average number of edges for a channel\n",
    "        avg_num_edges = avg_num_of_prevs_for_a_channel(layer, Is_class)\n",
    "        \n",
    "        # For all channels in layer\n",
    "        for channel, prev_inf_dict in enumerate(Is_class[layer]):\n",
    "            # Get source node\n",
    "            src = node_name(layer, channel)\n",
    "            \n",
    "            # Get branch\n",
    "            branch = get_branch(layer, channel, layer_fragment_sizes[layer])\n",
    "            \n",
    "            # If the channel is connected to a branch\n",
    "            if branch in [1, 2]:\n",
    "                # Get possible edge weights for the channel\n",
    "                channel_edges = {}\n",
    "                for prev_channel in prev_inf_dict:\n",
    "                    prev_inf = prev_inf_dict[prev_channel]\n",
    "                    \n",
    "                    # Extract influence information for prev_channel\n",
    "                    branch_layer = '{}_{}'.format(layer, branch)\n",
    "                    prev_prev_inf_dict = Is_class[branch_layer][int(prev_channel)]\n",
    "                    \n",
    "                    for prev_prev_channel in prev_prev_inf_dict:\n",
    "                        prev_prev_inf = prev_prev_inf_dict[prev_prev_channel]\n",
    "                        if prev_prev_channel not in channel_edges:\n",
    "                            channel_edges[prev_prev_channel] = []\n",
    "                        channel_edges[prev_prev_channel].append(min(prev_inf, prev_prev_inf))\n",
    "                        \n",
    "                # Get only one weight for each channel and prev_prev channel\n",
    "                for prev_prev_channel in channel_edges:\n",
    "                    channel_edges[prev_prev_channel] = max(channel_edges[prev_prev_channel])\n",
    "                \n",
    "                # Get top (avg_num_edges) prev_prev_channels based on the edge weight\n",
    "                top_prev_prevs_weights = sorted(channel_edges.items(), key=operator.itemgetter(1), reverse=True)\n",
    "                top_prev_prevs_weights = top_prev_prevs_weights[:avg_num_edges]\n",
    "                \n",
    "                # Add edges from channel and top_prev_prev_channel\n",
    "                for prev_prev_channel, weight in top_prev_prevs_weights:\n",
    "                    tgt = node_name(prev_layer, prev_prev_channel)\n",
    "                    G.add_edge(src, tgt, weight=weight)\n",
    "            \n",
    "            # If the channel is directly connected to the previous layer\n",
    "            elif branch in [0, 3]:\n",
    "                for prev_channel in prev_inf_dict:\n",
    "                    # Add edge of (src, tgt-prev)\n",
    "                    prev_inf = prev_inf_dict[prev_channel]\n",
    "                    tgt = node_name(prev_layer, prev_channel)\n",
    "                    G.add_edge(src, tgt, weight=prev_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dag(mixed_layers):\n",
    "    dag = {}\n",
    "    for layer in mixed_layers[::-1]:\n",
    "        dag[layer] = []\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personalization_dict(G, Ms, mixed_layers):\n",
    "    \n",
    "    personalization = {node: 1 for node in list(G.nodes)}\n",
    "\n",
    "    for layer in mixed_layers[::-1]:\n",
    "        M = Ms[layer]\n",
    "        for channel in range(M.shape[-1]):\n",
    "            node = layer + '-' + str(channel)\n",
    "            if node in personalization:\n",
    "                personalization[layer + '-' + str(channel)] = M[pred_class][channel]\n",
    "    \n",
    "    return personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for thresholding nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_mass(prob_mass_threshold, reverse_sorted_vals):\n",
    "    prob_mass = 0\n",
    "    threshold_cnt = 0\n",
    "    while prob_mass < prob_mass_threshold:\n",
    "        prob_mass += reverse_sorted_vals[threshold_cnt]\n",
    "        threshold_cnt += 1\n",
    "    threshold_val = reverse_sorted_vals[threshold_cnt]\n",
    "    return threshold_cnt, threshold_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(mixed_layers, pagerank, prob_mass_threshold=0.12):\n",
    "    # Get threshold value\n",
    "    pagerank_values = list(pagerank.values())\n",
    "    sorted_pagerank_vals = sorted(pagerank_values, reverse=True)\n",
    "    threshold_cnt, threshold_val = get_prob_mass(prob_mass_threshold, sorted_pagerank_vals)\n",
    "    \n",
    "    # Get thresholds\n",
    "    thresholds = {}\n",
    "    pagerank_sorted = sorted(pagerank.items(), key=operator.itemgetter(1))\n",
    "    for layer in mixed_layers[::-1]:\n",
    "        pageranks_layer = list(filter(lambda x: layer in x[0],  pagerank_sorted))\n",
    "        pagerank_values_layer = list(map(lambda x: x[1], pageranks_layer))\n",
    "        threshold = len(pagerank_values_layer) - np.searchsorted(np.array(pagerank_values_layer), 0.0007)\n",
    "        thresholds[layer] = max(min(threshold, len(pagerank_values_layer) - 1), 0)\n",
    "\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_val(mixed_layers, pagerank, prob_mass_threshold=0.12):\n",
    "    pagerank_values = list(pagerank.values())\n",
    "    sorted_pagerank_vals = sorted(pagerank_values, reverse=True)\n",
    "    threshold_cnt, threshold_val = get_prob_mass(prob_mass_threshold, sorted_pagerank_vals)\n",
    "    \n",
    "    return threshold_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholded_nodes(pagerank, threshold_val):\n",
    "    thresholded_nodes = {}\n",
    "    \n",
    "    for node in pagerank:\n",
    "        if pagerank[node] > threshold_val:\n",
    "            thresholded_nodes[node] = pagerank[node]\n",
    "        \n",
    "    return thresholded_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thresholded_edges(mixed_layers, G):\n",
    "    \n",
    "    thresholded_edges = {}\n",
    "    edge_checker = {}\n",
    "    for layer in mixed_layers[::-1]:\n",
    "        thresholded_edges[layer] = {}\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for edge in G.edges(node):\n",
    "            node1, node2 = edge\n",
    "            if (node1 not in thresholded_nodes) or (node2 not in thresholded_nodes):\n",
    "                continue\n",
    "\n",
    "            layer, channel, prev_layer, prev_channel = parse_edge(edge, mixed_layers)\n",
    "            if channel not in thresholded_edges[layer]:\n",
    "                thresholded_edges[layer][channel] = []\n",
    "\n",
    "            if (node1, node2) in edge_checker:\n",
    "                continue\n",
    "            elif (node2, node1) in edge_checker:\n",
    "                continue\n",
    "            edge_checker[(node1, node2)] = True\n",
    "\n",
    "            thresholded_edges[layer][channel].append({\n",
    "                'prev_channel': int(prev_channel),\n",
    "                'inf:': G.get_edge_data(*edge)['weight']\n",
    "            })\n",
    "    return thresholded_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edge(edge, mixed_layers):\n",
    "    n1_layer, n1_channel = edge[0].split('-')\n",
    "    n2_layer, n2_channel = edge[1].split('-')\n",
    "    \n",
    "    n1_idx, n2_idx = mixed_layers.index(n1_layer), mixed_layers.index(n2_layer)\n",
    "    \n",
    "    # If n1 is current layer, n2 is previous layer\n",
    "    if n1_idx > n2_idx:\n",
    "        layer, channel = n1_layer, n1_channel\n",
    "        prev_layer, prev_channel = n2_layer, n2_channel\n",
    "        \n",
    "    # If n1 is previous layer, n1 is current layer\n",
    "    else:\n",
    "        layer, channel = n2_layer, n2_channel\n",
    "        prev_layer, prev_channel = n1_layer, n1_channel\n",
    "    \n",
    "    return layer, channel, prev_layer, prev_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dag(mixed_layers, thresholded_nodes, thresholded_edges):\n",
    "    dag = {}\n",
    "    for layer in mixed_layers[::-1]:\n",
    "        dag[layer] = []\n",
    "        if layer == 'mixed3a':\n",
    "            M = Ms[layer]\n",
    "            for channel, cnt in enumerate(M[pred_class]):\n",
    "                dag[layer].append({\n",
    "                    'channel': int(channel),\n",
    "                    'count': int(cnt),\n",
    "                    'layer': layer,\n",
    "                    'prev_channels': []\n",
    "                })\n",
    "\n",
    "    for node in G.nodes():\n",
    "        for edge in G.edges(node):\n",
    "            node1, node2 = edge\n",
    "            if (node1 not in thresholded_nodes) or (node2 not in thresholded_nodes):\n",
    "                continue\n",
    "\n",
    "            layer, channel, prev_layer, prev_channel = parse_edge(edge, mixed_layers)\n",
    "            M = Ms[layer]\n",
    "            dag[layer].append({\n",
    "                'channel': int(channel),\n",
    "                'count': int(M[pred_class][int(channel)]),\n",
    "                'layer': layer,\n",
    "                'prev_channels': thresholded_edges[layer][channel]\n",
    "            })\n",
    "    return dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get inception_v1 model infromation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirpath = '/Users/haekyu/data/summit/'\n",
    "imgnet_dirpath = data_dirpath\n",
    "I_mat_dirpath = data_dirpath + 'I-matrices/'\n",
    "M_mat_dirpath = data_dirpath + 'M-matrices/'\n",
    "dag_dirpath = data_dirpath + 'dag/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.InceptionV1()\n",
    "googlenet.load_graphdef()\n",
    "nodes = googlenet.graph_def.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers = get_layers(nodes)\n",
    "mixed_layers = [layer for layer in all_layers if 'mixed' in layer]\n",
    "layer_fragment_sizes = {layer: get_channel_sizes(layer, nodes) for layer in mixed_layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(imgnet_dirpath + 'imagenet.json') as f:\n",
    "    imgnet = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_layer = 'mixed5b'\n",
    "end_layer = 'mixed3a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading  mixed5b , mixed5b_1 , mixed5b_2 \n",
      "loading  mixed5a , mixed5a_1 , mixed5a_2 \n",
      "loading  mixed4e , mixed4e_1 , mixed4e_2 \n",
      "loading  mixed4d , mixed4d_1 , mixed4d_2 \n",
      "loading  mixed4c , mixed4c_1 , mixed4c_2 \n",
      "loading  mixed4b , mixed4b_1 , mixed4b_2 \n",
      "loading  mixed4a , mixed4a_1 , mixed4a_2 \n",
      "loading  mixed3b , mixed3b_1 , mixed3b_2 \n",
      "loading  mixed3a , mixed3a_1 , mixed3a_2 "
     ]
    }
   ],
   "source": [
    "# Is = load_I_matrices(all_layers, start_layer, end_layer, I_mat_dirpath, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: 270\n",
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 5482\n",
      "Number of edges: 350335\n",
      "Average degree: 127.8128\n"
     ]
    }
   ],
   "source": [
    "num_class = 1000\n",
    "for pred_class in range(num_class):\n",
    "    if pred_class != 270:\n",
    "        continue\n",
    "    \n",
    "    # Extract influence information for the pred_class\n",
    "    # Is_class = extract_class_I_matrices(Is, all_layers, start_layer, end_layer, pred_class, verbose=False)\n",
    "    \n",
    "    # Initialize an undirected graph\n",
    "    # G = nx.Graph()\n",
    "    \n",
    "    # Generate full graph\n",
    "    # gen_full_graph(Is_class, G, mixed_layers)\n",
    "    \n",
    "    # Read M-matrices\n",
    "    Ms = read_Ms(M_mat_dirpath, mixed_layers)\n",
    "    \n",
    "    # Personalized pagerank to filter nodes\n",
    "    # personalization = get_personalization_dict(G, Ms, mixed_layers)\n",
    "    # pagerank = nx.pagerank(G, personalization=personalization, weight='weight', alpha=0.90)\n",
    "    \n",
    "    # Thresolding\n",
    "    threshold_val = get_threshold_val(mixed_layers, pagerank, prob_mass_threshold=0.12)\n",
    "    thresholded_nodes = get_thresholded_nodes(pagerank, threshold_val)\n",
    "    thresholded_edges = get_thresholded_edges(mixed_layers, G)\n",
    "    \n",
    "    # Generate dag in json format\n",
    "    dag = gen_dag(mixed_layers, thresholded_nodes, thresholded_edges)\n",
    "    \n",
    "    # Save the graph into a file\n",
    "    filename = dag_dirpath + 'pagerank/' + 'dag-{}.json'.format(pred_class)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dag, f, indent=2)\n",
    "                    \n",
    "    print('class:', pred_class)          \n",
    "    print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
